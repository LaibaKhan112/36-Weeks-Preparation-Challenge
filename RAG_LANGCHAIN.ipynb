{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM73Pb3tDdFa18tob9qXwAJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LaibaKhan112/36-Weeks-Preparation-Challenge/blob/main/RAG_LANGCHAIN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IbROR_66F0Z4"
      },
      "outputs": [],
      "source": [
        "!pip install -qU langchain-pinecone"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU langchain langchain_community langchain-core"
      ],
      "metadata": {
        "id": "5ut9kU0FMjdo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy==1.26.4 google-auth==2.43.0 --force-reinstall"
      ],
      "metadata": {
        "collapsed": true,
        "id": "i8gtjTmMN7mZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initializing Pinecone"
      ],
      "metadata": {
        "id": "84sZ8pPUJrRp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "PINECONE_API_KEY = userdata.get('PINECONE_API_KEY')\n",
        "PINECONE_API_KEY"
      ],
      "metadata": {
        "id": "qeer6HTUGC6v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pinecone import Pinecone\n",
        "pc = Pinecone(api_key = PINECONE_API_KEY)"
      ],
      "metadata": {
        "id": "-J7DYWdaG5Y_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from pinecone import ServerlessSpec\n",
        "\n",
        "index_name = \"my-langchain-project-02\"\n",
        "\n",
        "if not pc.has_index(index_name):\n",
        "  pc.create_index(\n",
        "      name= index_name,\n",
        "      dimension = 1024,\n",
        "      metric = \"cosine\",\n",
        "      spec = ServerlessSpec(\n",
        "          cloud = \"aws\", region = \"us-east-1\"\n",
        "  )\n",
        "  )\n",
        "\n",
        "index = pc.Index(index_name)"
      ],
      "metadata": {
        "id": "BWi8j0m_HFVl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Document Loader"
      ],
      "metadata": {
        "id": "dgq3o0KILBqf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU langchain-community pyPDF"
      ],
      "metadata": {
        "id": "HVH0RQlMIUVY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import PyPDFLoader"
      ],
      "metadata": {
        "id": "Im9wQ1JRLL3I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "JSYvU-IJPaSU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loader =PyPDFLoader(\"Laiba Khan.docx.pdf\")\n",
        "document = loader.load()"
      ],
      "metadata": {
        "id": "mmSrlIbSLsiI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "document[0]"
      ],
      "metadata": {
        "collapsed": true,
        "id": "NWeyg3nGP6Ig"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text Splitting"
      ],
      "metadata": {
        "id": "nyy9A1ilbvNT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U langchain-text-splitters"
      ],
      "metadata": {
        "collapsed": true,
        "id": "gvTFydHlcCms"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=300,\n",
        "    chunk_overlap=150\n",
        ")\n",
        "\n",
        "chunks = text_splitter.split_documents(document)\n",
        "\n",
        "print(chunks[1].page_content)\n"
      ],
      "metadata": {
        "id": "daozgllPcKeb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chunks"
      ],
      "metadata": {
        "collapsed": true,
        "id": "ttBew-hXeIw6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating Embeddings"
      ],
      "metadata": {
        "id": "lT2faFQcQfru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU langchain-google-genai"
      ],
      "metadata": {
        "collapsed": true,
        "id": "dycxkmYRP8Ml"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\n",
        "GOOGLE_API_KEY"
      ],
      "metadata": {
        "id": "tK3Jkx6-QuT-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "\n",
        "embeddings = GoogleGenerativeAIEmbeddings(\n",
        "    model = \"models/embedding-001\",\n",
        "    api_key=GOOGLE_API_KEY\n",
        ")\n",
        "\n",
        "texts = [chunk.page_content for chunk in chunks]\n",
        "\n",
        "vectors = embeddings.embed_documents(texts)\n",
        "\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "lAFU4rhYRAMj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "model = SentenceTransformer(\"intfloat/multilingual-e5-large\")\n",
        "vectors = model.encode(texts).tolist()\n",
        "\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "TrmG3P_xbIPN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(vectors[0]))\n"
      ],
      "metadata": {
        "id": "Ji6av4vgjO1E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from uuid import uuid4\n",
        "\n",
        "to_upsert = []\n",
        "for vec, text in zip(vectors, texts):\n",
        "    to_upsert.append((\n",
        "        str(uuid4()),\n",
        "        vec,\n",
        "        {\"text\": text}\n",
        "    ))\n",
        "\n",
        "# 3) Upsert into Pinecone\n",
        "index.upsert(vectors=to_upsert)\n",
        "\n",
        "print(\"Upserted:\", len(to_upsert))"
      ],
      "metadata": {
        "id": "tPQPAQPrlHpF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "spUBxS14kjfa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What is this PDF about?\"\n",
        "query_vector = model.encode(query).tolist()\n",
        "\n",
        "results = index.query(\n",
        "    vector=query_vector,\n",
        "    top_k=5,\n",
        "    include_metadata=True\n",
        ")\n",
        "\n",
        "\n",
        "for match in results[\"matches\"]:\n",
        "    print(\"Score:\", match[\"score\"])\n",
        "    print(match[\"metadata\"][\"text\"])\n",
        "    print(\"-----\")\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "54ocVs5GlDsy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model = \"gemini-2.5-flash\",\n",
        "    api_key = GOOGLE_API_KEY)"
      ],
      "metadata": {
        "id": "oO1dX8cUm1zb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google import genai\n",
        "\n",
        "llm = genai.Client(api_key=GOOGLE_API_KEY)\n",
        "\n",
        "def answer_to_user(query: str):\n",
        "\n",
        "    # 1) Embed user query\n",
        "    query_vector = model.encode(query).tolist()\n",
        "\n",
        "    # 2) Similarity search in Pinecone\n",
        "    results = index.query(\n",
        "        vector=query_vector,\n",
        "        top_k=2,\n",
        "        include_metadata=True,\n",
        "         # remove if you didnâ€™t use namespace\n",
        "    )\n",
        "\n",
        "    # 3) Collect matched text\n",
        "    context = \"\"\n",
        "    for match in results[\"matches\"]:\n",
        "        context += match[\"metadata\"][\"text\"] + \"\\n\\n\"\n",
        "\n",
        "    # 4) Ask LLM\n",
        "    prompt = f\"\"\"\n",
        "    Answer the question using the context below.\n",
        "    If answer not found in context, say \"Not found in document\".\n",
        "\n",
        "    Context:\n",
        "    {context}\n",
        "\n",
        "    Question:\n",
        "    {query}\n",
        "    \"\"\"\n",
        "\n",
        "    response = llm.models.generate_content(\n",
        "        model=\"gemini-2.5-flash\",\n",
        "        contents=prompt\n",
        "    )\n",
        "\n",
        "    return response.text\n",
        "\n"
      ],
      "metadata": {
        "id": "dZNgNz6foyfr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "answer_to_user(\"What is this PDF about ?\")"
      ],
      "metadata": {
        "id": "fKeNrhg2qYvz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "answer = answer_to_user(\"Who is  Laiba?\")\n",
        "print(answer)\n"
      ],
      "metadata": {
        "id": "wqWc2PoNqfzz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "answer = answer_to_user(\"What is the cgpa of laiba\")\n",
        "print(answer)\n"
      ],
      "metadata": {
        "id": "UwnJrSRhqpcK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(answer)"
      ],
      "metadata": {
        "id": "JRggdF6yrYCq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "H8_ew0tmrbny"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}