{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPYl45AzgWYqpRMKRvkHn9g",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LaibaKhan112/36-Weeks-Preparation-Challenge/blob/main/Function_Calling_Config.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "from google import genai\n",
        "from google.genai import types\n",
        "\n",
        "# ---------- 1) API KEY + CLIENT ----------\n",
        "API_KEY = userdata.get(\"GOOGLE_API_KEY\")\n",
        "client = genai.Client(api_key=API_KEY)   # IMPORTANT: no \"with ... as client\" (it closes the client)\n",
        "\n",
        "# ---------- 2) YOUR REAL PYTHON FUNCTIONS ----------\n",
        "def enable_lights():\n",
        "    print(\"LIGHTBOT : Lights enabled.\")\n",
        "    return \"lights_enabled\"\n",
        "\n",
        "def set_light_color(rgb_hex: str):\n",
        "    print(f\"LIGHTBOT : Lights set to {rgb_hex}\")\n",
        "    return f\"color_set_to_{rgb_hex}\"\n",
        "\n",
        "def stop_lights():\n",
        "    print(\"LIGHTBOT : Lights off.\")\n",
        "    return \"lights_off\"\n",
        "\n",
        "PY_TOOLS = {\n",
        "    \"enable_lights\": enable_lights,\n",
        "    \"set_light_color\": set_light_color,\n",
        "    \"stop_lights\": stop_lights,\n",
        "}\n",
        "\n",
        "# ---------- 3) TOOL (FUNCTION) DECLARATIONS ----------\n",
        "enable_lights_fn = {\n",
        "    \"name\": \"enable_lights\",\n",
        "    \"description\": \"Turn on the lighting system\",\n",
        "    \"parameters\": {\"type\": \"object\", \"properties\": {}},\n",
        "}\n",
        "\n",
        "set_light_color_fn = {\n",
        "    \"name\": \"set_light_color\",\n",
        "    \"description\": \"Set the light color using hex RGB value (example: #FFA500)\",\n",
        "    \"parameters\": {\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\"rgb_hex\": {\"type\": \"string\"}},\n",
        "        \"required\": [\"rgb_hex\"],\n",
        "    },\n",
        "}\n",
        "\n",
        "stop_lights_fn = {\n",
        "    \"name\": \"stop_lights\",\n",
        "    \"description\": \"Turn off the lighting system\",\n",
        "    \"parameters\": {\"type\": \"object\", \"properties\": {}},\n",
        "}\n",
        "\n",
        "tools = [\n",
        "    types.Tool(\n",
        "        function_declarations=[enable_lights_fn, set_light_color_fn, stop_lights_fn]\n",
        "    )\n",
        "]\n",
        "\n",
        "config = types.GenerateContentConfig(\n",
        "    tools=tools,\n",
        "    system_instruction=(\n",
        "        \"You are a lighting system bot. \"\n",
        "        \"If the user requests an action, you MUST call a tool. \"\n",
        "        \"Never claim you did an action unless you called the tool.\"\n",
        "    ),\n",
        ")\n",
        "\n",
        "# ---------- 4) CREATE A CHAT ----------\n",
        "chat = client.chats.create(\n",
        "    model=\"gemini-2.5-flash\",\n",
        "    config=config,\n",
        ")\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "2P3Esmf7iZWO"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- 5) SIMPLE TOOL LOOP ----------\n",
        "def ask(prompt: str):\n",
        "    resp = chat.send_message(prompt)\n",
        "    print(f\"Response: {resp}\")\n",
        "\n",
        "    while True:\n",
        "        part = resp.candidates[0].content.parts[0]\n",
        "\n",
        "        # If no tool call, we are done\n",
        "        if not getattr(part, \"function_call\", None):\n",
        "            print(\"MODEL:\", resp.text)\n",
        "            return resp\n",
        "\n",
        "        fc = part.function_call\n",
        "        name = fc.name\n",
        "        args = fc.args or {}\n",
        "\n",
        "        print(\"TOOL CALL:\", name, args)\n",
        "\n",
        "        # Run python tool\n",
        "        result = PY_TOOLS[name](**args) if args else PY_TOOLS[name]()\n",
        "        if result is None:\n",
        "            result = \"ok\"\n",
        "\n",
        "        # âœ… Send tool result back as a Part (NOT Content)\n",
        "        resp = chat.send_message(\n",
        "            types.Part(\n",
        "                function_response=types.FunctionResponse(\n",
        "                    name=name,\n",
        "                    response={\"result\": result},\n",
        "                )\n",
        "            )\n",
        "        )"
      ],
      "metadata": {
        "id": "H49bgh70mG_J"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EQZepSFcrdWO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- 6) TEST ----------\n",
        "ask(\"Turn the lights off?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TJeS_n9kiaTy",
        "outputId": "f5cc9595-67ee-49a3-d781-a07fc7b3f4d6"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Response: sdk_http_response=HttpResponse(\n",
            "  headers=<dict len=10>\n",
            ") candidates=[Candidate(\n",
            "  content=Content(\n",
            "    parts=[\n",
            "      Part(\n",
            "        function_call=FunctionCall(\n",
            "          args={},\n",
            "          name='stop_lights'\n",
            "        ),\n",
            "        thought_signature=b'\\n\\xba\\x01\\x01r\\xc8\\xda|\\xfe\\xfc\\x10VOo]\\xb7\\xd6\\x83s\\xe2\\xbbgo\\xd9\\xc77V\\xc10u\\xca=\\x9b\\xa0tj0_G\\x15\\xfe\\xb4\\xf8E\\xf04\\xef3\\x1b\\xa4v1\\xad\\x88\\x8d\\x98\\xc3\\x03\\xb9\\xb0\\x16\\xb8].\\xc2\\x0c\\xa5\\x9aJK\\xa9S\\x0c9\\xf6\\xc5\\xa6y\\x99W\\xf0\\x9e\\xbb7\\xd0;c\\xbf\\xe1\\x05{\\xadrd\\x86\\xe5\\x98...'\n",
            "      ),\n",
            "    ],\n",
            "    role='model'\n",
            "  ),\n",
            "  finish_reason=<FinishReason.STOP: 'STOP'>,\n",
            "  index=0\n",
            ")] create_time=None model_version='gemini-2.5-flash' prompt_feedback=None response_id='m097aY6aKLOOjMcP7vjSgAs' usage_metadata=GenerateContentResponseUsageMetadata(\n",
            "  candidates_token_count=10,\n",
            "  prompt_token_count=168,\n",
            "  prompt_tokens_details=[\n",
            "    ModalityTokenCount(\n",
            "      modality=<MediaModality.TEXT: 'TEXT'>,\n",
            "      token_count=168\n",
            "    ),\n",
            "  ],\n",
            "  thoughts_token_count=36,\n",
            "  total_token_count=214\n",
            ") automatic_function_calling_history=None parsed=None\n",
            "TOOL CALL: stop_lights {}\n",
            "LIGHTBOT : Lights off.\n",
            "MODEL: I've turned the lights off.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GenerateContentResponse(\n",
              "  candidates=[\n",
              "    Candidate(\n",
              "      content=Content(\n",
              "        parts=[\n",
              "          Part(\n",
              "            text=\"I've turned the lights off.\"\n",
              "          ),\n",
              "        ],\n",
              "        role='model'\n",
              "      ),\n",
              "      finish_reason=<FinishReason.STOP: 'STOP'>,\n",
              "      index=0\n",
              "    ),\n",
              "  ],\n",
              "  model_version='gemini-2.5-flash',\n",
              "  response_id='nE97aeWZCpix-sAPpNe5gQM',\n",
              "  sdk_http_response=HttpResponse(\n",
              "    headers=<dict len=10>\n",
              "  ),\n",
              "  usage_metadata=GenerateContentResponseUsageMetadata(\n",
              "    candidates_token_count=8,\n",
              "    prompt_token_count=195,\n",
              "    prompt_tokens_details=[\n",
              "      ModalityTokenCount(\n",
              "        modality=<MediaModality.TEXT: 'TEXT'>,\n",
              "        token_count=195\n",
              "      ),\n",
              "    ],\n",
              "    total_token_count=203\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UfsCDDHDiw7b"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}